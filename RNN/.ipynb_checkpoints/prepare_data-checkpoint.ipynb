{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sys\n",
    "import math\n",
    "import datetime \n",
    "from random import shuffle\n",
    "stdout = sys.stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN_DIR = '/root/kaggle/restaurantAvis/cache/' #Alain\n",
    "MAIN_DIR = '' #Guillaume\n",
    "\n",
    "TRAINEDMODEL = MAIN_DIR + 'model_multi_lstm1.ckpt'\n",
    "VOCAB_ALL = MAIN_DIR + 'vocab_all.txt'\n",
    "MOTS_NECESSAIRES = MAIN_DIR + 'mots_necessaires.txt'\n",
    "DATASET_DIR = '../'\n",
    "\n",
    "\n",
    "X_TRAIN_CSV = MAIN_DIR + 'X_train.csv'\n",
    "Y_TRAIN_CSV = MAIN_DIR + 'y_train.csv'\n",
    "X_DEV_CSV = MAIN_DIR + 'X_dev.csv'\n",
    "Y_DEV_CSV = MAIN_DIR + 'y_dev.csv'\n",
    "PRETRAINED_VOCAB_CSV = MAIN_DIR + 'pretrained_vocab.csv'\n",
    "TO_TRAIN_VOCAB_CSV = MAIN_DIR + 'to_train_vocab.csv'\n",
    "ONE_HOT_COLS_CSV = MAIN_DIR + 'one_hot_cols.csv'\n",
    "\n",
    "EMBS_CSV = MAIN_DIR + 'pretrained_embs_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "dev = pd.read_csv(DATASET_DIR + 'Restaurant_Reviews.tsv', delimiter='\\t', quoting=3)\n",
    "train = pd.read_csv(DATASET_DIR + 'newdata/1-restaurant-train.tsv', delimiter='\\t', quoting=3)\n",
    "# train = pd.read_csv(os.path.join(data_path, 'train.csv'), dtype=dtype, low_memory=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review    82065\n",
      "Liked     82065\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Thank you thank you thank you !! I  want to t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"A Humane Society store at the Biltmore?  Inte...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Don't buy Nike sneakers if you want to return ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"I have to say I love most things about Sprout...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"The tire pressure light came on a day or so a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0  \"Thank you thank you thank you !! I  want to t...      4\n",
       "1  \"A Humane Society store at the Biltmore?  Inte...      5\n",
       "2  Don't buy Nike sneakers if you want to return ...      1\n",
       "3  \"I have to say I love most things about Sprout...      3\n",
       "4  \"The tire pressure light came on a day or so a...      5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.count())\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review    1000\n",
      "Liked     1000\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dev.count())\n",
    "dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to clean the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(data):\n",
    "        data = data.replace('\\\\n',' ').replace('\\\\r',' ')\n",
    "        lower_case = data.lower()\n",
    "        letters_only = re.sub(\"[^A-Za-z]\",\" \", lower_case)\n",
    "        words = letters_only.split()\n",
    "        return \" \".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the whole vocabulary and the most used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_list(filepath, a_list):\n",
    "    with open(filepath, 'w') as f:\n",
    "        for item in a_list:\n",
    "            f.write(\"{}\\n\".format(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92334\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,1),stop_words=frozenset([]))\n",
    "vectorizer.fit(train[\"Review\"])\n",
    "mots_utiles = set(vectorizer.vocabulary_)\n",
    "del vectorizer\n",
    "\n",
    "gc.collect()\n",
    "save_list(MOTS_UTILES,mots_utiles)\n",
    "print(len(mots_utiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9221\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=50,stop_words=frozenset([]))\n",
    "vectorizer.fit(train[\"Review\"])\n",
    "mots_necessaires = set(vectorizer.vocabulary_)\n",
    "del vectorizer\n",
    "gc.collect()\n",
    "save_list(MOTS_NECESSAIRES,mots_necessaires)\n",
    "print(len(mots_necessaires))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On recr√©e les champs de texte \"students\" et \"project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank you thank you thank you i want to thank ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a humane society store at the biltmore interes...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>don t buy nike sneakers if you want to return ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i have to say i love most things about sprouts...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the tire pressure light came on a day or so ag...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0  thank you thank you thank you i want to thank ...      4\n",
       "1  a humane society store at the biltmore interes...      5\n",
       "2  don t buy nike sneakers if you want to return ...      1\n",
       "3  i have to say i love most things about sprouts...      3\n",
       "4  the tire pressure light came on a day or so ag...      5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Preprocess data   \n",
    "def extract_features(df):\n",
    "    df['Review'] = df.apply(lambda row: clean_text( \n",
    "        str(row['Review'])\n",
    "        ), axis=1)\n",
    "\n",
    "extract_features(train)\n",
    "extract_features(dev)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimate the optimal size for the RNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023\n",
      "191.61598732711875\n",
      "333.0\n"
     ]
    }
   ],
   "source": [
    "train['review_len'] = train['Review'].apply(lambda x: len(x.split()))\n",
    "dev['review_len'] = dev['Review'].apply(lambda x: len(x.split()))\n",
    "print(max(train['review_len']))\n",
    "print(train['review_len'].mean())\n",
    "print(train['review_len'].quantile(q=0.90))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the embedded words vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_glove(dim):\n",
    "    vocab = np.loadtxt(\"../tools//embedding/glove.6B/glove.6B.\" + str(dim) + \"d.txt\",delimiter = ' ',dtype='str',comments=None,usecols=0)\n",
    "    vectors = np.loadtxt(\"../tools//embedding/glove.6B/glove.6B.\" + str(dim) + \"d.txt\",delimiter = ' ',comments=None,usecols=(i+1 for i in range(dim)))\n",
    "    return vocab, vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the' ',' '.' 'of' 'to' 'and' 'in' 'a' '\"' \"'s\"]\n",
      "[[ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
      "  -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
      "  -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
      "  -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
      "  -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
      "   4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
      "   1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
      "  -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
      "  -1.1514e-01 -7.8581e-01]\n",
      " [ 1.3441e-02  2.3682e-01 -1.6899e-01  4.0951e-01  6.3812e-01  4.7709e-01\n",
      "  -4.2852e-01 -5.5641e-01 -3.6400e-01 -2.3938e-01  1.3001e-01 -6.3734e-02\n",
      "  -3.9575e-01 -4.8162e-01  2.3291e-01  9.0201e-02 -1.3324e-01  7.8639e-02\n",
      "  -4.1634e-01 -1.5428e-01  1.0068e-01  4.8891e-01  3.1226e-01 -1.2520e-01\n",
      "  -3.7512e-02 -1.5179e+00  1.2612e-01 -2.4420e-02 -4.2961e-02 -2.8351e-01\n",
      "   3.5416e+00 -1.1956e-01 -1.4533e-02 -1.4990e-01  2.1864e-01 -3.3412e-01\n",
      "  -1.3872e-01  3.1806e-01  7.0358e-01  4.4858e-01 -8.0262e-02  6.3003e-01\n",
      "   3.2111e-01 -4.6765e-01  2.2786e-01  3.6034e-01 -3.7818e-01 -5.6657e-01\n",
      "   4.4691e-02  3.0392e-01]\n",
      " [ 1.5164e-01  3.0177e-01 -1.6763e-01  1.7684e-01  3.1719e-01  3.3973e-01\n",
      "  -4.3478e-01 -3.1086e-01 -4.4999e-01 -2.9486e-01  1.6608e-01  1.1963e-01\n",
      "  -4.1328e-01 -4.2353e-01  5.9868e-01  2.8825e-01 -1.1547e-01 -4.1848e-02\n",
      "  -6.7989e-01 -2.5063e-01  1.8472e-01  8.6876e-02  4.6582e-01  1.5035e-02\n",
      "   4.3474e-02 -1.4671e+00 -3.0384e-01 -2.3441e-02  3.0589e-01 -2.1785e-01\n",
      "   3.7460e+00  4.2284e-03 -1.8436e-01 -4.6209e-01  9.8329e-02 -1.1907e-01\n",
      "   2.3919e-01  1.1610e-01  4.1705e-01  5.6763e-02 -6.3681e-05  6.8987e-02\n",
      "   8.7939e-02 -1.0285e-01 -1.3931e-01  2.2314e-01 -8.0803e-02 -3.5652e-01\n",
      "   1.6413e-02  1.0216e-01]]\n"
     ]
    }
   ],
   "source": [
    "pretrained_vocab, pretrained_embs = load_pretrained_glove(50)\n",
    "_, pretrained_embs_100 = load_pretrained_glove(100)\n",
    "_, pretrained_embs_300 = load_pretrained_glove(300)\n",
    "print(pretrained_vocab[:10])\n",
    "print(pretrained_embs[:3,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On enl√®ve les mots inutiles pour traiter le jeu de donn√©es (test et train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343793\n"
     ]
    }
   ],
   "source": [
    "# nettoyer des mots non utilis√©s\n",
    "mots_inutiles = [i for i in range(len(pretrained_vocab)) if pretrained_vocab[i] not in mots_utiles]\n",
    "print(len(mots_inutiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56207,)\n",
      "(56207, 50)\n",
      "(56207, 100)\n"
     ]
    }
   ],
   "source": [
    "pretrained_vocab = np.delete(pretrained_vocab, (mots_inutiles), axis=0)\n",
    "pretrained_embs = np.delete(pretrained_embs, (mots_inutiles), axis=0)\n",
    "pretrained_embs_100 = np.delete(pretrained_embs_100, (mots_inutiles), axis=0)\n",
    "pretrained_embs_300 = np.delete(pretrained_embs_300, (mots_inutiles), axis=0)\n",
    "print(pretrained_vocab.shape)\n",
    "print(pretrained_embs.shape)\n",
    "print(pretrained_embs_100.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule le vocabulaire connu par l'application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349\n",
      "56556\n"
     ]
    }
   ],
   "source": [
    "only_in_train = mots_necessaires - set(pretrained_vocab)\n",
    "only_in_train = list(only_in_train)\n",
    "only_in_train.append(\"<BLANK>\")\n",
    "vocab = list(pretrained_vocab) + only_in_train\n",
    "print(len(only_in_train))\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "REVIEW_LENGTH = 333\n",
    "def preprocess_text(data,length):\n",
    "        data = str(data).split()\n",
    "        if len(data) < length :\n",
    "            data = data +['<BLANK>' for i in range(length - len(data))]\n",
    "        return ' '.join(data[:length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Review'] = train['Review'].apply(lambda x:preprocess_text(x,REVIEW_LENGTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "      <th>review_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank you thank you thank you i want to thank ...</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a humane society store at the biltmore interes...</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>don t buy nike sneakers if you want to return ...</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked  review_len\n",
       "0  thank you thank you thank you i want to thank ...      4          96\n",
       "1  a humane society store at the biltmore interes...      5         151\n",
       "2  don t buy nike sneakers if you want to return ...      1         148"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(train, train['Liked'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(X_TRAIN_CSV)\n",
    "y_train.to_csv(Y_TRAIN_CSV)\n",
    "X_dev.to_csv(X_DEV_CSV)\n",
    "y_dev.to_csv(Y_DEV_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(PRETRAINED_VOCAB_CSV, pretrained_vocab, delimiter=';',fmt='%s')\n",
    "np.savetxt(TO_TRAIN_VOCAB_CSV, only_in_train, delimiter=';',fmt='%s')\n",
    "np.savetxt(EMBS_CSV + '50.csv', pretrained_embs, delimiter=';')\n",
    "np.savetxt(EMBS_CSV + '100.csv', pretrained_embs_100, delimiter=';')\n",
    "np.savetxt(EMBS_CSV + '300.csv', pretrained_embs_300, delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
